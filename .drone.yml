---
kind: pipeline
name: deploy-to-cluster
type: docker
clone:
  disable: true
# depends_on:
# - build-image


environment:
  # path to openmina tooling
  OM: helm/openmina-config
  # target height to wait for after deployment
  TARGET_HEIGHT: 8
  # resource to wait for status when deploying Mina seeds
  SEEDS_WAIT_RESOURCE: deployment/seed1
  # timeout to wait when deploying Mina seeds
  SEEDS_WAIT_TIMEOUT: 10m
  # resource to wait for status when deploying Mina nodes
  NODES_WAIT_RESOURCE: deployment/node1
  # timeout to wait when deploying Mina nodes
  NODES_WAIT_TIMEOUT: 15m
  # retries to check all nodes to be at the same level
  HEIGHT_WAIT_RETRIES: 20
  # period to wait before retrying
  HEIGHT_WAIT_PERIOD: 15

defs:
- &log
  image: alpine/k8s:1.26.1
  detach: true
  environment:
    KUBECONFIG: kube-config
  commands:
  - while ! kubectl logs deployment/$${NAME} --container mina --follow; do echo "waiting for $${NAME} to start..."; sleep 10; done

steps:

- name: clone
  image: alpine/git
  commands:
  - git clone $${OPENMINA_REPO:-https://github.com/openmina/mina} --depth 1 -b $${OPENMINA_BRANCH:-openmina-legacy-snark-workers} .

- name: prepare-kubeconfig
  image: alpine/k8s:1.26.1
  environment:
    DRONE_KUBECONFIG:
      from_secret: k8s_config
    KUBECONFIG: kube-config
  commands:
  - umask 0077
  - echo "$DRONE_KUBECONFIG" > $${KUBECONFIG}
  - kubectl config set-context --current --namespace $${NAMESPACE:-testnet}

- name: delete-old-testnet
  image: alpine/k8s:1.26.1
  environment:
    KUBECONFIG: kube-config
  commands:
  - $${OM}/deploy.sh delete --all --force
  - sleep 10
  - |
    PODS="$$($${OM}/kube-utils.sh mina-pods)"
    if [ -n "$${PODS}" ]; then
        echo "Workaround for pods left running, force-delete pods $$PODS"
        kubectl delete --force pods $${PODS} || true
    fi
  - helm delete zkapp-server-continuous --wait --timeout=1m || true
  - helm delete zkapp-send-continuous --wait --timeout=5m || true

- name: prepare-deamon-json
  image: alpine/k8s:1.26.1
  commands:
  - $${OM}/generate-conf-file.sh --slot-duration=$${SLOT_DURATION:-180} $${SLOTS_PER_EPOCH:+--slots-per-epoch=$${SLOTS_PER_EPOCH}} > $${OM}/resources/daemon.json

- name: log-seed
  <<: *log
  environment:
    NAME: seed1

- name: log-node
  <<: *log
  environment:
    NAME: node1

- name: log-producer
  <<: *log
  environment:
    NAME: node1

- name: log-snarker
  <<: *log
  environment:
    NAME: snarker001

- name: deploy-nodes
  image: alpine/k8s:1.26.1
  environment:
    KUBECONFIG: kube-config
  commands:
  # - export MINA_IMAGE="openmina/mina:mina-daily-$${MINA_BRANCH:-develop}-${DRONE_BUILD_NUMBER}"
  - export MINA_IMAGE="minaprotocol/mina-daemon:2.0.0rampup6-4061884-bullseye-berkeley"
  - HELM_ARGS="--set=healthcheck.failureThreshold=1800 $${HELM_ARGS}"
  - $${OM}/deploy.sh deploy --seeds --force -- $${HELM_ARGS}
  - sleep 30 # handicap to other nodes so seed nodes to be up when they become needed
  - $${OM}/deploy.sh deploy --producers --nodes --force -- $${HELM_ARGS}
  - $${OM}/deploy.sh deploy --snark-workers --force -- $${HELM_ARGS}
  - $${OM}/update-frontend.sh -- --set=isVanilla=true

- name: testnet-is-ready
  image: alpine/k8s:1.26.1
  environment:
    KUBECONFIG: kube-config
  commands:
  - $${OM}/kube-utils.sh mina-testnet-available $${NODES_WAIT_TIMEOUT}
  - $${OM}/kube-utils.sh mina-testnet-same-height $${HEIGHT_WAIT_RETRIES} $${HEIGHT_WAIT_PERIOD}

- name: deployment-info
  image: alpine/k8s:1.26.1
  environment:
    KUBECONFIG: kube-config
  commands:
  - PORT="$$($${OM}/kube-utils.sh frontend-port $${NAMESPACE:-testnet})"
  - 'echo "Frontend: http://1.k8.openmina.com:$PORT"'
  - 'echo "Namespace: $${NAMESPACE:-testnet}"'
  - echo
  - 'echo Seed nodes: $(kubectl get pods -l role=seed -o name | wc -l)'
  - 'echo Producer nodes: $(kubectl get pods -l role=block-producer -o name | wc -l)'
  - 'echo Snark coordinator nodes: $(kubectl get pods -l role=snark-coordinator -o name | wc -l)'
  - 'echo Snark worker nodes: $(kubectl get pods -l role=snark-worker -o name | wc -l)'
  - 'echo Plain nodes: $(kubectl get pods -l role=plain-node -o name | wc -l)'

